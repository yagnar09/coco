{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.63s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np \n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import pandas as pd \n",
    "\n",
    "cap = dset.CocoCaptions(root = 'train2014',\n",
    "                        annFile = 'captions_train2014.json',\n",
    "                        transform=transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.36s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "cap_val = dset.CocoCaptions(root = 'val2014',\n",
    "                        annFile = 'captions_val2014.json',\n",
    "                        transform=transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  82783\n",
      "Image Size:  torch.Size([3, 224, 224])\n",
      "['Closeup of bins of food that include broccoli and bread.', 'A meal is presented in brightly colored plastic trays.', 'there are containers filled with different kinds of foods', 'Colorful dishes holding meat, vegetables, fruit, and bread.', 'A bunch of trays that have different food.']\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples: ', len(cap))\n",
    "img, target = cap[0] # load 4th sample\n",
    "\n",
    "print(\"Image Size: \", img.size())\n",
    "print(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ASUSROG/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=True)\n",
    "trainloader = torch.utils.data.DataLoader(cap,batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " valloader =  torch.utils.data.DataLoader(cap_val,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNencoder,self).__init__()\n",
    "        self.densenet = models.densenet201(pretrained=True)\n",
    "        self.densenet=torch.nn.Sequential(*(list(self.densenet.children())[:-1]))\n",
    "    def forward(self, images):\n",
    "        out = self.densenet(images)  \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstmEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(lstmEncoder,self).__init__()\n",
    "        self.lstm=nn.LSTM(embed_size,hidden_size,num_layers)\n",
    "        self.linear=nn.Linear(hidden_size,vocab_size)\n",
    "        self.dropout=nn.Dropout(0.5)\n",
    "    def forward(self,features,captions):\n",
    "        embeddings=self.dropout(self.embed(captions))\n",
    "        embeddings=torch.cat((features.unsqueeze(0),embeddings),dim=0)\n",
    "        hiddens,_=self.lstm(embeddings)\n",
    "        outputs=self.linear(hiddens)\n",
    "        return outputs\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUSROG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUSROG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.74s)\n",
      "creating index...\n",
      "index created!\n",
      "[0/414113] tokenized the captions.\n",
      "[100000/414113] tokenized the captions.\n",
      "[200000/414113] tokenized the captions.\n",
      "[300000/414113] tokenized the captions.\n",
      "[400000/414113] tokenized the captions.\n",
      "total number of words in vocab: 9949\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "nltk.download('punkt')\n",
    "import nltk\n",
    "from collections import Counter\n",
    "nltk.download('punkt')\n",
    "from pycocotools.coco import COCO\n",
    "class Vocabulary(object):\n",
    "  def __init__(self):\n",
    "    self.word2idx = {}\n",
    "    self.idx2word = {}\n",
    "    self.idx = 0\n",
    "\n",
    "  def add_word(self, word):\n",
    "    if not word in self.word2idx:\n",
    "      self.word2idx[word] = self.idx\n",
    "      self.idx2word[self.idx] = word\n",
    "      self.idx += 1\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.word2idx)\n",
    "\n",
    "  def encode(self, word):\n",
    "    if not word in self.word2idx:\n",
    "      return self.word2idx['[unk]']\n",
    "    return self.word2idx[word]\n",
    "\n",
    "  def decode(self, idx):\n",
    "    return self.idx2word[idx]\n",
    "\n",
    "\n",
    "def build_vocab(json='captions_train2014.json',\n",
    "                threshold=4,\n",
    "                max_words=15000):\n",
    "    coco = COCO(json)\n",
    "    counter = Counter()\n",
    "    ids = coco.anns.keys()\n",
    "    for i, id in enumerate(ids):\n",
    "        caption = str(coco.anns[id]['caption'])\n",
    "        tokens = nltk.tokenize.word_tokenize(caption.lower())\n",
    "        counter.update(tokens)\n",
    "\n",
    "        if i % 100000 == 0:\n",
    "            print('[%d/%d] tokenized the captions.' % (i, len(ids)))\n",
    "\n",
    "    words = counter.most_common(max_words - 5)\n",
    "    words = [word for word, cnt in words if cnt >= threshold]\n",
    "\n",
    "    vocab = Vocabulary()\n",
    "    vocab.add_word('[pad]')\n",
    "    vocab.add_word('[start]')\n",
    "    vocab.add_word('[end]')\n",
    "    vocab.add_word('[cls]')\n",
    "    vocab.add_word('[unk]')\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        vocab.add_word(word)\n",
    "    print('total number of words in vocab:', vocab.__len__())\n",
    "    return vocab, words\n",
    "\n",
    "\n",
    "nltk_tokenizer, words = build_vocab()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
